{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\r\n",
    "Very similar to arrays & matrices.  Used for inputs/outputs, as well as model parameters.\r\n",
    "\r\n",
    "Specifically, similar to NumPy's arrays but able to run on GPUs, etc.  When on cpu, they share the same underlying memory so you can switch between libraries easily.\r\n",
    "\r\n",
    "Tensors are also optimized for automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing tensors ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\r\n",
    "x_data = torch.tensor(data) # directly from data\r\n",
    "\r\n",
    "np_array = np.array(data)\r\n",
    "x_np = torch.from_numpy(np_array) # from numpy\r\n",
    "\r\n",
    "# ... from another tensor, from tensor generating functions \r\n",
    "# (e.g. rand, ones), etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attributes of a tensor\r\n",
    "Commonly used ones: shape, datatype, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\r\n",
    "\r\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\r\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\r\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on tensors\r\n",
    "Lots exist--mostly replicating NumPy as well as having some of its own functionality.  Each operation can be run on both CPU and GPU.\r\n",
    "\r\n",
    "By default, tensors created on the CPU.  Have to explicitly move it to gpu using .to(), or specify it at definition time.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to gpu if available\r\n",
    "if torch.cuda.is_available():\r\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otherwise it's mostly like numpy\r\n",
    "Slicing is similar, as are basic arithmatic (including the @ symbol).  tensor.xx() is much better supported as well--that is most functions have both a torch.function(tensor1, tensor2), as well as a tensor1.funciton(tensor2) version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-element tensors\r\n",
    "Slightly different.  Single element tensors have to be explicitly converted to a scalar using tensor.item():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\r\n",
    "agg = tensor.sum()\r\n",
    "agg_item = agg.item()\r\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place operations\r\n",
    "In-place operations (those that store the result in the operand) are denoted by a _ suffic.  e.g. `x.copy_(y), x.t_()` will both change `x`.\r\n",
    "\r\n",
    "Unlike numpy, the use of this is discouraged.  The reason is that it can be problematic when computing derivates due to the immedate loss of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\r\n",
    "tensor.add_(5)\r\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Bridge\r\n",
    "Tensors on the CPU and Numpy arrays can share their underlying memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\r\n",
    "print(f\"t: {t}\")\r\n",
    "n = t.numpy()\r\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change in the tensor reflects in the numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\r\n",
    "print(f\"t: {t}\")\r\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the other direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\r\n",
    "t = torch.from_numpy(n)\r\n",
    "\r\n",
    "np.add(n, 1, out=n)\r\n",
    "print(f\"t: {t}\")\r\n",
    "print(f\"n: {n}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0a10ce0df86bd47f20d28ed217e21e989a0ba99322e6d590bf6db2a306ca8d1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pytorch_tutorials': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}