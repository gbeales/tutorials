{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\r\n",
    "Section that runs through the API for common tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision import datasets\r\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data\r\n",
    "training_data = datasets.FashionMNIST(\r\n",
    "    root=\"data\",\r\n",
    "    train=True,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor()\r\n",
    ")\r\n",
    "\r\n",
    "# Download test data\r\n",
    "test_data = datasets.FashionMNIST(\r\n",
    "    root=\"data\",\r\n",
    "    train=False,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor()\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: pass the Datset as an argument to Dataloader, which wraps an iterable over hte dataset and supports automatic batching, sampling, shuffling, and mulitprocess data loading.  Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\r\n",
    "\r\n",
    "# Create data loaders\r\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\r\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\r\n",
    "\r\n",
    "for X, y in test_dataloader:\r\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\r\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\r\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\r\n",
    "To define a neural network in PyTorch, we create a class that inherits from nn.Module.  The layers of the network are defined in the ``__init__`` function, and specify how data will pass through the network in the ``forward`` function.  To accelerate opterations in the neural network, we move it to the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\r\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "print(\"Using {} device.\".format(device))\r\n",
    "\r\n",
    "# Define model\r\n",
    "class NeuralNetwork(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(NeuralNetwork, self).__init__()\r\n",
    "        self.flatten = nn.Flatten()\r\n",
    "        self.linear_relu_stack = nn.Sequential(\r\n",
    "            nn.Linear(28*28, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 10),\r\n",
    "            nn.ReLU()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.flatten(x)\r\n",
    "        logits = self.linear_relu_stack(x)\r\n",
    "        return logits\r\n",
    "\r\n",
    "model = NeuralNetwork().to(device)\r\n",
    "print(model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters\r\n",
    "... make loss function, add optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()  # what's this one??\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)    # Stochastic Gradient Descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and backpropagates the prediction error to adjust the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        X, y = X.to(device), y.to(device)\r\n",
    "\r\n",
    "        # compute prediction error\r\n",
    "        pred = model(X)\r\n",
    "        loss = loss_fn(pred, y)\r\n",
    "\r\n",
    "        # Backpropagation\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        if batch % 100 == 0:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And setup test function as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= size\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training conducted over iterations/epochs.  We train, then print accuracy/loss after each epoch to get an idea as to how the accuracy changes with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "------------------\n",
      "loss: 2.296291 [    0/60000]\n",
      "loss: 2.293638 [ 6400/60000]\n",
      "loss: 2.282891 [12800/60000]\n",
      "loss: 2.283813 [19200/60000]\n",
      "loss: 2.260386 [25600/60000]\n",
      "loss: 2.243879 [32000/60000]\n",
      "loss: 2.262010 [38400/60000]\n",
      "loss: 2.239266 [44800/60000]\n",
      "loss: 2.252949 [51200/60000]\n",
      "loss: 2.219981 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 0.034744 \n",
      "\n",
      "Epoch 2\n",
      "------------------\n",
      "loss: 2.222712 [    0/60000]\n",
      "loss: 2.215355 [ 6400/60000]\n",
      "loss: 2.183740 [12800/60000]\n",
      "loss: 2.210006 [19200/60000]\n",
      "loss: 2.136893 [25600/60000]\n",
      "loss: 2.103092 [32000/60000]\n",
      "loss: 2.170690 [38400/60000]\n",
      "loss: 2.100867 [44800/60000]\n",
      "loss: 2.137300 [51200/60000]\n",
      "loss: 2.102443 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 0.032483 \n",
      "\n",
      "Epoch 3\n",
      "------------------\n",
      "loss: 2.074734 [    0/60000]\n",
      "loss: 2.052762 [ 6400/60000]\n",
      "loss: 1.983814 [12800/60000]\n",
      "loss: 2.081375 [19200/60000]\n",
      "loss: 1.932110 [25600/60000]\n",
      "loss: 1.877612 [32000/60000]\n",
      "loss: 2.025376 [38400/60000]\n",
      "loss: 1.889771 [44800/60000]\n",
      "loss: 1.965272 [51200/60000]\n",
      "loss: 1.955384 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.029401 \n",
      "\n",
      "Epoch 4\n",
      "------------------\n",
      "loss: 1.860834 [    0/60000]\n",
      "loss: 1.833191 [ 6400/60000]\n",
      "loss: 1.730438 [12800/60000]\n",
      "loss: 1.930883 [19200/60000]\n",
      "loss: 1.712661 [25600/60000]\n",
      "loss: 1.651424 [32000/60000]\n",
      "loss: 1.886674 [38400/60000]\n",
      "loss: 1.695621 [44800/60000]\n",
      "loss: 1.794247 [51200/60000]\n",
      "loss: 1.846132 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.026728 \n",
      "\n",
      "Epoch 5\n",
      "------------------\n",
      "loss: 1.657574 [    0/60000]\n",
      "loss: 1.644625 [ 6400/60000]\n",
      "loss: 1.516555 [12800/60000]\n",
      "loss: 1.809548 [19200/60000]\n",
      "loss: 1.552441 [25600/60000]\n",
      "loss: 1.490184 [32000/60000]\n",
      "loss: 1.782592 [38400/60000]\n",
      "loss: 1.562549 [44800/60000]\n",
      "loss: 1.662946 [51200/60000]\n",
      "loss: 1.765900 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.024805 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... that's impressively bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "A common way to save a model is to serialize the internal state dictionary (basically pickle it?).  Makes sense though--the definition and the state is all that's needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "Loading a model includes re-creating the structure and then loading the state dicitonary into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Dress\", Actual: \"Trouser\"\n"
     ]
    }
   ],
   "source": [
    "# and let's evaluate it!\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[2][0], test_data[2][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x173c4cad5e0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data[3][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Trouser'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[test_data[2][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0a10ce0df86bd47f20d28ed217e21e989a0ba99322e6d590bf6db2a306ca8d1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pytorch_tutorials': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}